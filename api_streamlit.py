# -*- coding: utf-8 -*-
"""api_streamlit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pRlpmSWHyDsfXreijVxm9lGIzx0xQ_nL
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import model_from_json
import streamlit as st

idToWord=pd.read_csv('idToWord.csv')

vocab_size=len(idToWord)
max_sequence_len=60

model_bi = tf.keras.models.Sequential([    
    tf.keras.layers.Embedding(vocab_size,64,input_length=max_sequence_len),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(18, activation='softmax')
])

# load weights into bi model
model_bi.load_weights("model_weights.h5")
print("Loaded model from disk")

def text_cleaning(text):
    ids=[idToWord[idToWord.word==w]['id'].values[0] if idToWord.word.isin([w]).any() else 0 for w in text.split()]
    X_padded = np.zeros(max_sequence_len)
    if len(ids)>max_sequence_len:
        X_padded = ids[:max_sequence_len]
    else:
        X_padded[:len(ids)]=ids
    return(X_padded.reshape(1,60))

def predict(X):
    dialect={'3':'مصرى',  
    '11':'فلسطيني', 
    '6':'كويتي', 
    '8':'ليبي',  
    '12':'قطري',  
    '5':'اردني',  
    '7':'لبناني',  
    '13':'سعودي',  
    '0':'امراتي',  
    '1':'بحريني',  
    '10':'عماني',  
    '15':'سوري',  
    '2':'جزائري',  
    '4':'عراقي',  
    '14':'سوداني',  
    '9':'مغربي',  
    '17':'يمني',   
    '16':'تونسي'}
    
    return dialect[str(np.argmax(model_bi.predict(X), axis=-1)[0])]

title=st.text_input('اكتب التويتة')
lang=predict(text_cleaning(title))
st.write(lang)